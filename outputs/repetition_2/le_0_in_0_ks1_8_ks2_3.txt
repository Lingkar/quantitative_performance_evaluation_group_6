2020-10-22 16:53:07 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-10-22 16:53:08 INFO  SparkContext:54 - Running Spark version 2.3.1
2020-10-22 16:53:08 INFO  SparkContext:54 - Submitted application: lenet5
2020-10-22 16:53:08 INFO  SecurityManager:54 - Changing view acls to: buijnstersjan
2020-10-22 16:53:08 INFO  SecurityManager:54 - Changing modify acls to: buijnstersjan
2020-10-22 16:53:08 INFO  SecurityManager:54 - Changing view acls groups to: 
2020-10-22 16:53:08 INFO  SecurityManager:54 - Changing modify acls groups to: 
2020-10-22 16:53:08 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(buijnstersjan); groups with view permissions: Set(); users  with modify permissions: Set(buijnstersjan); groups with modify permissions: Set()
2020-10-22 16:53:08 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 38799.
2020-10-22 16:53:08 INFO  SparkEnv:54 - Registering MapOutputTracker
2020-10-22 16:53:08 INFO  SparkEnv:54 - Registering BlockManagerMaster
2020-10-22 16:53:08 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020-10-22 16:53:08 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2020-10-22 16:53:08 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-aa972116-abd8-4d75-9480-60b60d480d7e
2020-10-22 16:53:08 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2020-10-22 16:53:08 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2020-10-22 16:53:08 INFO  log:192 - Logging initialized @3233ms
2020-10-22 16:53:09 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2020-10-22 16:53:09 INFO  Server:414 - Started @3389ms
2020-10-22 16:53:09 INFO  AbstractConnector:278 - Started ServerConnector@684075c0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-10-22 16:53:09 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2020-10-22 16:53:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@726410a{/jobs,null,AVAILABLE,@Spark}
2020-10-22 16:53:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@35cb1e1a{/jobs/json,null,AVAILABLE,@Spark}
2020-10-22 16:53:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@366cf3c1{/jobs/job,null,AVAILABLE,@Spark}
2020-10-22 16:53:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@678fdcba{/jobs/job/json,null,AVAILABLE,@Spark}
2020-10-22 16:53:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@ad9259f{/stages,null,AVAILABLE,@Spark}
2020-10-22 16:53:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5bfa2dfe{/stages/json,null,AVAILABLE,@Spark}
2020-10-22 16:53:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@721ffd72{/stages/stage,null,AVAILABLE,@Spark}
2020-10-22 16:53:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22c5fd80{/stages/stage/json,null,AVAILABLE,@Spark}
2020-10-22 16:53:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2f3c60c7{/stages/pool,null,AVAILABLE,@Spark}
2020-10-22 16:53:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@20f3981a{/stages/pool/json,null,AVAILABLE,@Spark}
2020-10-22 16:53:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5dd1a35c{/storage,null,AVAILABLE,@Spark}
2020-10-22 16:53:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@50f57c9b{/storage/json,null,AVAILABLE,@Spark}
2020-10-22 16:53:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1c03141a{/storage/rdd,null,AVAILABLE,@Spark}
2020-10-22 16:53:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@200c7cc8{/storage/rdd/json,null,AVAILABLE,@Spark}
2020-10-22 16:53:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7017e0d6{/environment,null,AVAILABLE,@Spark}
2020-10-22 16:53:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@bfd5beb{/environment/json,null,AVAILABLE,@Spark}
2020-10-22 16:53:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@fda2d4a{/executors,null,AVAILABLE,@Spark}
2020-10-22 16:53:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4cf3fa45{/executors/json,null,AVAILABLE,@Spark}
2020-10-22 16:53:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32da25d{/executors/threadDump,null,AVAILABLE,@Spark}
2020-10-22 16:53:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@626e83d0{/executors/threadDump/json,null,AVAILABLE,@Spark}
2020-10-22 16:53:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c0042aa{/static,null,AVAILABLE,@Spark}
2020-10-22 16:53:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b9730de{/,null,AVAILABLE,@Spark}
2020-10-22 16:53:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@120599fd{/api,null,AVAILABLE,@Spark}
2020-10-22 16:53:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6cfc0299{/jobs/job/kill,null,AVAILABLE,@Spark}
2020-10-22 16:53:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@858aa3f{/stages/stage/kill,null,AVAILABLE,@Spark}
2020-10-22 16:53:09 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://bigdl.europe-west4-a.c.massive-network-289210.internal:4040
2020-10-22 16:53:09 INFO  SparkContext:54 - Added JAR file:///home/am72ghiassi/bd/spark/lib/bigdl-SPARK_2.3-0.11.0-jar-with-dependencies.jar at spark://bigdl.europe-west4-a.c.massive-network-289210.internal:38799/jars/bigdl-SPARK_2.3-0.11.0-jar-with-dependencies.jar with timestamp 1603385589403
2020-10-22 16:53:09 INFO  SparkContext:54 - Added file file:/home/am72ghiassi/bd/quantitative_performance_evaluation_group_6/lenet5.py at spark://bigdl.europe-west4-a.c.massive-network-289210.internal:38799/files/lenet5.py with timestamp 1603385589455
2020-10-22 16:53:09 INFO  Utils:54 - Copying /home/am72ghiassi/bd/quantitative_performance_evaluation_group_6/lenet5.py to /tmp/spark-8668e3ee-8118-4254-9352-a7265a4fb2ea/userFiles-e867ee9a-fd48-4bcd-a675-7027526123ad/lenet5.py
2020-10-22 16:53:09 INFO  SparkContext:54 - Added file file:///home/am72ghiassi/bd/spark/lib/bigdl-0.11.0-python-api.zip at spark://bigdl.europe-west4-a.c.massive-network-289210.internal:38799/files/bigdl-0.11.0-python-api.zip with timestamp 1603385589466
2020-10-22 16:53:09 INFO  Utils:54 - Copying /home/am72ghiassi/bd/spark/lib/bigdl-0.11.0-python-api.zip to /tmp/spark-8668e3ee-8118-4254-9352-a7265a4fb2ea/userFiles-e867ee9a-fd48-4bcd-a675-7027526123ad/bigdl-0.11.0-python-api.zip
2020-10-22 16:53:09 ERROR SparkContext:91 - Error initializing SparkContext.
org.apache.spark.SparkException: Invalid master URL: spark://:7077
	at org.apache.spark.util.Utils$.extractHostPortFromSparkUrl(Utils.scala:2452)
	at org.apache.spark.rpc.RpcAddress$.fromSparkURL(RpcAddress.scala:47)
	at org.apache.spark.deploy.client.StandaloneAppClient$$anonfun$1.apply(StandaloneAppClient.scala:52)
	at org.apache.spark.deploy.client.StandaloneAppClient$$anonfun$1.apply(StandaloneAppClient.scala:52)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.deploy.client.StandaloneAppClient.<init>(StandaloneAppClient.scala:52)
	at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.start(StandaloneSchedulerBackend.scala:116)
	at org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:164)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:500)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:238)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)
2020-10-22 16:53:09 INFO  AbstractConnector:318 - Stopped Spark@684075c0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-10-22 16:53:09 INFO  SparkUI:54 - Stopped Spark web UI at http://bigdl.europe-west4-a.c.massive-network-289210.internal:4040
2020-10-22 16:53:09 INFO  StandaloneSchedulerBackend:54 - Shutting down all executors
2020-10-22 16:53:09 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Asking each executor to shut down
2020-10-22 16:53:09 ERROR Utils:91 - Uncaught exception in thread Thread-6
java.lang.NullPointerException
	at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.org$apache$spark$scheduler$cluster$StandaloneSchedulerBackend$$stop(StandaloneSchedulerBackend.scala:226)
	at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.stop(StandaloneSchedulerBackend.scala:124)
	at org.apache.spark.scheduler.TaskSchedulerImpl.stop(TaskSchedulerImpl.scala:508)
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:1755)
	at org.apache.spark.SparkContext$$anonfun$stop$8.apply$mcV$sp(SparkContext.scala:1931)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1360)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1930)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:579)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:238)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)
2020-10-22 16:53:09 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2020-10-22 16:53:09 INFO  MemoryStore:54 - MemoryStore cleared
2020-10-22 16:53:09 INFO  BlockManager:54 - BlockManager stopped
2020-10-22 16:53:09 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2020-10-22 16:53:09 WARN  MetricsSystem:66 - Stopping a MetricsSystem that is not running
2020-10-22 16:53:09 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2020-10-22 16:53:09 INFO  SparkContext:54 - Successfully stopped SparkContext
Traceback (most recent call last):
  File "/home/am72ghiassi/bd/quantitative_performance_evaluation_group_6/lenet5.py", line 66, in <module>
    sc = SparkContext(appName="lenet5", conf=create_spark_conf())
  File "/home/am72ghiassi/bd/spark/python/lib/pyspark.zip/pyspark/context.py", line 118, in __init__
  File "/home/am72ghiassi/bd/spark/python/lib/pyspark.zip/pyspark/context.py", line 180, in _do_init
  File "/home/am72ghiassi/bd/spark/python/lib/pyspark.zip/pyspark/context.py", line 282, in _initialize_context
  File "/home/am72ghiassi/bd/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1525, in __call__
  File "/home/am72ghiassi/bd/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py", line 328, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.
: org.apache.spark.SparkException: Invalid master URL: spark://:7077
	at org.apache.spark.util.Utils$.extractHostPortFromSparkUrl(Utils.scala:2452)
	at org.apache.spark.rpc.RpcAddress$.fromSparkURL(RpcAddress.scala:47)
	at org.apache.spark.deploy.client.StandaloneAppClient$$anonfun$1.apply(StandaloneAppClient.scala:52)
	at org.apache.spark.deploy.client.StandaloneAppClient$$anonfun$1.apply(StandaloneAppClient.scala:52)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.deploy.client.StandaloneAppClient.<init>(StandaloneAppClient.scala:52)
	at org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.start(StandaloneSchedulerBackend.scala:116)
	at org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:164)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:500)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:238)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)

2020-10-22 16:53:09 INFO  ShutdownHookManager:54 - Shutdown hook called
2020-10-22 16:53:09 INFO  ShutdownHookManager:54 - Deleting directory /tmp/localPyFiles-248df949-d894-4a61-85a4-6226535604f1
2020-10-22 16:53:09 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-2c312993-3a99-4be9-a47b-310e41692a91
2020-10-22 16:53:09 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-8668e3ee-8118-4254-9352-a7265a4fb2ea
